<div>
  <div>Status: </div>
  <div id="status"></div>
  <div id="averageWordSpeed"></div>
  <div id="averageTokenSpeed"></div>
  <p></p>
  <div id="input">Prompt: Write me an extra-long poem</div>
  <p></p>
  <div>Output:</div>
  <div id="output"></div>
</div>
<script type="module">
  "use strict";

  import { env, AutoTokenizer } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers';

  async function main() {
    const canCreate = await window.ai.canCreateTextSession();
    if (canCreate === "no") {
      document.getElementById("status").innerHTML = "Can't create a session";
      return;
    }

    const session = await window.ai.createTextSession();
    const input = document.getElementById("input").innerHTML;
    const outputElement = document.getElementById("output");
    const averageWordSpeedElement = document.getElementById("averageWordSpeed");
    const averageTokenSpeedElement = document.getElementById("averageTokenSpeed");
    let previousLength = 0;
    const stream = session.promptStreaming(input);
    const startTime = performance.now();
    let endTime, elapsedTime, wordCount, averageWordSpeed;
    for await (const chunk of stream) {
      endTime = performance.now();
      elapsedTime = endTime - startTime;
      outputElement.innerHTML += chunk.slice(previousLength);
      previousLength = chunk.length;
      wordCount = chunk.split(/\s+/).length;
      averageWordSpeed = (wordCount / (elapsedTime / 1000)).toFixed(2);
      averageWordSpeedElement.innerHTML = `Average Word Speed: ${averageWordSpeed} words/s`;
    }

    env.allowLocalModels = false;
    const tokenizer = await AutoTokenizer.from_pretrained('Xenova/gemma-tokenizer');
    const tokenIds = tokenizer.encode(outputElement.innerHTML);
    const tokenCount = tokenIds.length;
    const averageTokenSpeed = (tokenCount / (elapsedTime / 1000)).toFixed(2);
    averageTokenSpeedElement.innerHTML = `Average Token Speed: ${averageTokenSpeed} tokens/s`;
  }

  main();

</script>