<div>
  <div>Status: </div>
  <div id="status"></div>
  <div id="wps"></div>
  <div id="tps"></div>
  <p></p>
  <div id="input">Prompt: Write me an long poem</div>
  <p></p>
  <div>Output:</div>
  <div id="output"></div>
</div>
<script type="module">
  "use strict";

  import { env, AutoTokenizer } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers';

  async function main() {
    const { available, defaultTemperature, defaultTopK, maxTopK } = await ai.languageModel?.capabilities();

    if (available === 'no') {
      console.log('AI assistant is not available');
      return;
    }

    const session = await ai.languageModel.create();
    const input = document.getElementById("input").innerHTML;
    const outputElement = document.getElementById("output");
    const wpsElement = document.getElementById("wps");
    const tpsElement = document.getElementById("tps");
    let previousLength = 0;
    const stream = session.promptStreaming(input);
    const startTime = performance.now();
    let endTime, elapsedTime, wordCount, wps;
    for await (const chunk of stream) {
      endTime = performance.now();
      elapsedTime = endTime - startTime;
      outputElement.innerHTML += chunk.slice(previousLength);
      previousLength = chunk.length;
      wordCount = chunk.split(/\s+/).length;
      wps = (wordCount / (elapsedTime / 1000)).toFixed(2);
      wpsElement.innerHTML = `words/s: ${wps}`;
    }

    env.allowLocalModels = true;
    env.localModelPath = 'models';
    const tokenizer = await AutoTokenizer.from_pretrained('Xenova/gemma-tokenizer');
    const tokenIds = tokenizer.encode(outputElement.innerHTML);
    const tokenCount = tokenIds.length;
    const tps = (tokenCount / (elapsedTime / 1000)).toFixed(2);
    tpsElement.innerHTML = `tokens/s: ${tps}`;
  }

  main();

</script>